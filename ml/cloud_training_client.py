#!/usr/bin/env python3
"""
Cloud Training Client
Automates the process of sending voice data to cloud platforms and retrieving trained models
"""

import os
import sys
import json
import time
import subprocess
import tempfile
import requests
from pathlib import Path
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CloudTrainingClient:
    def __init__(self):
        self.temp_dir = Path(tempfile.mkdtemp(prefix="cloud_training_"))
        self.colab_notebook_url = None
        self.kaggle_kernel_url = None
        
    def prepare_training_package(self, user_id: str, voice_dir: str = None) -> Optional[Path]:
        """Prepare voice data package for cloud training."""
        try:
            from secure_transfer import SecureVoiceTransfer
            
            if not voice_dir:
                voice_dir = "/home/luke/personal-ai-clone/web/public/voices"
            
            transfer = SecureVoiceTransfer(voice_dir)
            
            # Generate encryption key
            encryption_key = transfer.generate_encryption_key()
            logger.info(f"ğŸ”‘ Generated encryption key: {encryption_key[:20]}...")\n            \n            # Package voice data\n            package_path = transfer.package_voice_data(user_id)\n            if not package_path:\n                logger.error("Failed to package voice data")\n                return None\n            \n            # Encrypt package\n            encrypted_path = transfer.encrypt_package(package_path)\n            if not encrypted_path:\n                logger.error("Failed to encrypt package")\n                return None\n            \n            # Save encryption key for later use\n            key_file = self.temp_dir / f"{user_id}_encryption_key.txt"\n            with open(key_file, 'w') as f:\n                f.write(encryption_key)\n            \n            logger.info(f"âœ… Training package ready: {encrypted_path.name}")\n            logger.info(f"ğŸ” Encryption key saved: {key_file.name}")\n            \n            return encrypted_path\n            \n        except Exception as e:\n            logger.error(f"Failed to prepare training package: {e}")\n            return None\n    \n    def upload_to_colab(self, package_path: Path, user_id: str) -> bool:\n        \"\"\"Upload training package to Google Colab storage.\"\"\"\n        try:\n            logger.info("ğŸ“¤ Uploading to Google Colab temporary storage...")\n            \n            # For Google Colab, we'll use the file upload widget in the notebook\n            # This prepares the package for manual upload\n            \n            colab_dir = self.temp_dir / "colab_upload"\n            colab_dir.mkdir(exist_ok=True)\n            \n            # Copy package to upload directory\n            upload_package = colab_dir / f"voice_training_{user_id}.zip"\n            import shutil\n            shutil.copy2(package_path, upload_package)\n            \n            # Create upload instructions\n            instructions = {\n                "platform": "google_colab",\n                "user_id": user_id,\n                "package_file": upload_package.name,\n                "upload_instructions": [\n                    "1. Open the hybrid_voice_training_colab.ipynb notebook in Google Colab",\n                    "2. Run the first few cells to set up the environment",\n                    f"3. In the file upload section, select: {upload_package.name}",\n                    "4. Run the training pipeline cells",\n                    "5. Download the trained model when complete"\n                ],\n                "encryption_key_file": f"{user_id}_encryption_key.txt",\n                "created_at": datetime.now().isoformat()\n            }\n            \n            instructions_file = colab_dir / "upload_instructions.json"\n            with open(instructions_file, 'w') as f:\n                json.dump(instructions, f, indent=2)\n            \n            logger.info(f"ğŸ“‹ Upload package prepared: {colab_dir}")\n            logger.info(f"ğŸ“„ Instructions: {instructions_file}")\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f"Failed to prepare Colab upload: {e}")\n            return False\n    \n    def upload_to_kaggle(self, package_path: Path, user_id: str) -> bool:\n        \"\"\"Upload training package to Kaggle dataset.\"\"\"\n        try:\n            logger.info("ğŸ“¤ Uploading to Kaggle dataset...")\n            \n            # Check if Kaggle API is configured\n            kaggle_config = Path.home() / ".kaggle" / "kaggle.json"\n            if not kaggle_config.exists():\n                logger.error("Kaggle API not configured. Please set up ~/.kaggle/kaggle.json")\n                return False\n            \n            # Create Kaggle dataset structure\n            dataset_dir = self.temp_dir / "kaggle_dataset"\n            dataset_dir.mkdir(exist_ok=True)\n            \n            # Copy package to dataset\n            dataset_package = dataset_dir / f"voice_training_data.zip"\n            import shutil\n            shutil.copy2(package_path, dataset_package)\n            \n            # Create dataset metadata\n            dataset_metadata = {\n                "title": f"Voice Training Data {user_id}",\n                "id": f"your-username/voice-training-{user_id.replace('_', '-')}",\n                "licenses": [{"name": "other"}],\n                "resources": [\n                    {\n                        "path": "voice_training_data.zip",\n                        "description": "Encrypted voice training data"\n                    }\n                ]\n            }\n            \n            metadata_file = dataset_dir / "dataset-metadata.json"\n            with open(metadata_file, 'w') as f:\n                json.dump(dataset_metadata, f, indent=2)\n            \n            # Upload to Kaggle using API\n            try:\n                cmd = ["kaggle", "datasets", "create", "-p", str(dataset_dir)]\n                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n                \n                if result.returncode == 0:\n                    logger.info("âœ… Dataset uploaded to Kaggle successfully")\n                    logger.info(f"ğŸ”— Dataset URL: https://www.kaggle.com/datasets/{dataset_metadata['id']}")\n                    return True\n                else:\n                    logger.error(f"Kaggle upload failed: {result.stderr}")\n                    return False\n                    \n            except subprocess.TimeoutExpired:\n                logger.error("Kaggle upload timed out")\n                return False\n            except FileNotFoundError:\n                logger.error("Kaggle CLI not found. Install with: pip install kaggle")\n                return False\n            \n        except Exception as e:\n            logger.error(f"Failed to upload to Kaggle: {e}")\n            return False\n    \n    def monitor_training_progress(self, platform: str, job_id: str = None) -> Dict[str, Any]:\n        \"\"\"Monitor training progress on cloud platform.\"\"\"\n        # This would integrate with platform APIs to monitor training\n        # For now, return manual monitoring instructions\n        \n        monitoring_info = {\n            "platform": platform,\n            "job_id": job_id,\n            "status": "manual_monitoring_required",\n            "instructions": []\n        }\n        \n        if platform == "google_colab":\n            monitoring_info["instructions"] = [\n                "1. Open your Google Colab notebook",\n                "2. Check the training progress in the output cells",\n                "3. Monitor GPU usage and memory consumption",\n                "4. Training typically takes 30-90 minutes depending on data size",\n                "5. Download the model when training completes"\n            ]\n        elif platform == "kaggle":\n            monitoring_info["instructions"] = [\n                "1. Open your Kaggle kernel",\n                "2. Monitor the training logs and metrics",\n                "3. Check for any out-of-memory errors",\n                "4. Download results when kernel completes",\n                "5. Training time varies based on GPU allocation"\n            ]\n        \n        return monitoring_info\n    \n    def download_trained_model(self, download_path: str, user_id: str) -> bool:\n        \"\"\"Download and install trained model from cloud.\"\"\"\n        try:\n            logger.info(f"ğŸ“¥ Processing downloaded model for {user_id}...")\n            \n            download_file = Path(download_path)\n            if not download_file.exists():\n                logger.error(f"Download file not found: {download_path}")\n                return False\n            \n            # Get encryption key\n            key_file = self.temp_dir / f"{user_id}_encryption_key.txt"\n            if not key_file.exists():\n                logger.error(f"Encryption key not found: {key_file}")\n                logger.info("Please provide the encryption key manually")\n                return False\n            \n            with open(key_file, 'r') as f:\n                encryption_key = f.read().strip()\n            \n            # Use secure transfer to install model\n            from secure_transfer import SecureVoiceTransfer\n            transfer = SecureVoiceTransfer()\n            transfer.encryption_key = encryption_key.encode()\n            \n            success = transfer.install_trained_model(download_file, user_id)\n            \n            if success:\n                logger.info("âœ… Model installed successfully!")\n                logger.info("ğŸ”„ Restarting inference server to load new model...")\n                self.restart_inference_server()\n                return True\n            else:\n                logger.error("âŒ Failed to install model")\n                return False\n                \n        except Exception as e:\n            logger.error(f"Failed to process downloaded model: {e}")\n            return False\n    \n    def restart_inference_server(self) -> bool:\n        \"\"\"Restart the local inference server to load new models.\"\"\"\n        try:\n            # Send restart signal to Docker container\n            cmd = ["docker", "restart", "personal-ai-clone-ml-inference-1"]\n            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)\n            \n            if result.returncode == 0:\n                logger.info("âœ… Inference server restarted")\n                \n                # Wait for server to be ready\n                time.sleep(10)\n                \n                # Test server health\n                try:\n                    response = requests.get("http://localhost:8000/health", timeout=10)\n                    if response.status_code == 200:\n                        logger.info("âœ… Inference server is healthy")\n                        return True\n                    else:\n                        logger.warning(f"Server health check failed: {response.status_code}")\n                        return False\n                except requests.RequestException as e:\n                    logger.warning(f"Failed to check server health: {e}")\n                    return False\n            else:\n                logger.error(f"Failed to restart server: {result.stderr}")\n                return False\n                \n        except Exception as e:\n            logger.error(f"Failed to restart inference server: {e}")\n            return False\n    \n    def generate_colab_url(self, user_id: str) -> str:\n        \"\"\"Generate Google Colab URL with pre-filled notebook.\"\"\"\n        # Base URL for the notebook\n        notebook_path = "ml/hybrid_voice_training_colab.ipynb"\n        \n        # Create GitHub URL (assuming notebook is in repository)\n        github_url = f"https://github.com/yourusername/personal-ai-clone/blob/main/{notebook_path}"\n        \n        # Generate Colab URL\n        colab_url = f"https://colab.research.google.com/github/yourusername/personal-ai-clone/blob/main/{notebook_path}"\n        \n        return colab_url\n    \n    def cleanup(self):\n        \"\"\"Clean up temporary files.\"\"\"\n        if self.temp_dir.exists():\n            import shutil\n            shutil.rmtree(self.temp_dir, ignore_errors=True)\n            logger.info("ğŸ—‘ï¸ Temporary files cleaned up")\n\ndef main():\n    \"\"\"Command line interface for cloud training.\"\"\"\n    import argparse\n    \n    parser = argparse.ArgumentParser(description="Cloud Voice Training Client")\n    parser.add_argument("command", choices=["prepare", "upload", "download", "monitor"], \n                       help="Command to execute")\n    parser.add_argument("--user-id", required=True, help="User ID for voice training")\n    parser.add_argument("--platform", choices=["colab", "kaggle"], default="colab",\n                       help="Cloud platform to use")\n    parser.add_argument("--voice-dir", help="Custom voice directory path")\n    parser.add_argument("--download-path", help="Path to downloaded model file")\n    \n    args = parser.parse_args()\n    \n    client = CloudTrainingClient()\n    \n    try:\n        if args.command == "prepare":\n            print(f"ğŸ“¦ Preparing training package for {args.user_id}...")\n            package_path = client.prepare_training_package(args.user_id, args.voice_dir)\n            \n            if package_path:\n                print(f"âœ… Package ready: {package_path}")\n                print(f"ğŸ”‘ Encryption key saved in: {client.temp_dir}")\n                \n                # Auto-upload based on platform\n                if args.platform == "colab":\n                    client.upload_to_colab(package_path, args.user_id)\n                    colab_url = client.generate_colab_url(args.user_id)\n                    print(f"ğŸ”— Open notebook: {colab_url}")\n                elif args.platform == "kaggle":\n                    client.upload_to_kaggle(package_path, args.user_id)\n            else:\n                print("âŒ Failed to prepare package")\n                \n        elif args.command == "upload":\n            print(f"ğŸ“¤ Uploading to {args.platform}...")\n            # Implementation depends on platform\n            print("Manual upload required. Use 'prepare' command for full workflow.")\n            \n        elif args.command == "download":\n            if not args.download_path:\n                print("âŒ --download-path required for download command")\n                return\n            \n            print(f"ğŸ“¥ Processing downloaded model for {args.user_id}...")\n            success = client.download_trained_model(args.download_path, args.user_id)\n            \n            if success:\n                print("âœ… Model installed and inference server restarted")\n                print("ğŸ¯ Your new voice model is ready to use!")\n            else:\n                print("âŒ Failed to install model")\n                \n        elif args.command == "monitor":\n            print(f"ğŸ‘€ Monitoring training on {args.platform}...")\n            info = client.monitor_training_progress(args.platform)\n            \n            print(f"Platform: {info['platform']}")\n            print(f"Status: {info['status']}")\n            print("\\nInstructions:")\n            for i, instruction in enumerate(info['instructions'], 1):\n                print(f"  {i}. {instruction}")\n    \n    finally:\n        client.cleanup()\n\nif __name__ == "__main__":\n    main()\n